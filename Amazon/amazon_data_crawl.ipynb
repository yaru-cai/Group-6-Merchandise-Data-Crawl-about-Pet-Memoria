{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8a100e-79f1-41d1-ae18-08fbb3058948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "\n",
    "def convert_sales_volume(sales_str):\n",
    "    if 'K' in sales_str:\n",
    "        num = sales_str.replace('+', '').replace('K', '000')\n",
    "    else:\n",
    "        num = sales_str.replace('+', '')\n",
    "    try:\n",
    "        return int(num)\n",
    "    except ValueError:\n",
    "        return None  # 如果转换失败返回 None\n",
    "\n",
    "# 设置Chrome驱动程序\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 打开Amazon的搜索页面\n",
    "url = 'https://www.amazon.com/s?k=pet+memorial&language=en_US&crid=2XEALO4SBIQ18&sprefix=pet+memorial%2Caps%2C707&ref=nb_sb_noss_1'\n",
    "driver.get(url)\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# 打开CSV文件，准备写入\n",
    "with open('amazon_pet_memorial.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Price\", \"Rating\", \"Rating Count\", \"ASIN\", \"Monthly Sales\", \"Image URL\", \"Product URL\"])\n",
    "\n",
    "    # 循环处理每页数据\n",
    "    while True:\n",
    "        # 等待页面加载\n",
    "        time.sleep(3)\n",
    "\n",
    "        # 计算15秒后的时间点\n",
    "        end_time = time.time() + 15\n",
    "\n",
    "        # 滚动页面，直到时间结束\n",
    "        while time.time() < end_time:\n",
    "            driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "            time.sleep(1)  # 暂停1秒以等待页面加载\n",
    "\n",
    "        # 定位包含所有商品的大div\n",
    "        container = driver.find_element(By.CLASS_NAME, 's-main-slot.s-result-list.s-search-results.sg-row')\n",
    "\n",
    "        # 获取所有商品信息\n",
    "        items = container.find_elements(By.XPATH, './/div[@data-asin]')\n",
    "\n",
    "        for item in items:\n",
    "            try:\n",
    "                # 提取ASIN\n",
    "                asin = item.get_attribute('data-asin')\n",
    "\n",
    "                # 标题\n",
    "                title = item.find_element(By.XPATH, './/h2/a/span').text if item.find_elements(By.XPATH, './/h2/a/span') else \"N/A\"\n",
    "\n",
    "                # 价格\n",
    "                price = \"N/A\"\n",
    "                price_elements = item.find_elements(By.XPATH, './/span[@class=\"a-price-whole\"]')\n",
    "                if price_elements:\n",
    "                    price_whole = price_elements[0].text.replace(',', '')\n",
    "                    price_fraction = item.find_element(By.XPATH, './/span[@class=\"a-price-fraction\"]').text\n",
    "                    price = f\"{price_whole}.{price_fraction}\"\n",
    "\n",
    "                # 评分\n",
    "                rating = item.find_element(By.XPATH, './/i[contains(@class, \"a-icon-star\")]/span').get_attribute(\"innerHTML\").split(' ')[0] if item.find_elements(By.XPATH, './/i[contains(@class, \"a-icon-star\")]') else \"N/A\"\n",
    "\n",
    "                # 评分数量\n",
    "                rating_count = item.find_element(By.XPATH, './/span[@class=\"a-size-base s-underline-text\"]').text.replace(',', '') if item.find_elements(By.XPATH, './/span[@class=\"a-size-base s-underline-text\"]') else \"N/A\"\n",
    "\n",
    "                # 月销量\n",
    "                monthly_sales_elements = item.find_elements(By.XPATH,\n",
    "                                                             './/span[contains(@class, \"a-color-secondary\") and contains(text(), \"bought in past month\")]')\n",
    "                monthly_sales = monthly_sales_elements[0].text if monthly_sales_elements else \"N/A\"\n",
    "                monthly_sales_number = convert_sales_volume(re.search(r'\\d+K?\\+', monthly_sales).group(0)) if monthly_sales != \"N/A\" else \"N/A\"\n",
    "\n",
    "                # 图片URL\n",
    "                image_url = item.find_element(By.XPATH, './/img[@class=\"s-image\"]').get_attribute(\"src\") if item.find_elements(By.XPATH, './/img[@class=\"s-image\"]') else \"N/A\"\n",
    "\n",
    "                # 商品链接\n",
    "                product_url = item.find_element(By.XPATH, './/h2/a').get_attribute(\"href\") if item.find_elements(By.XPATH, './/h2/a') else \"N/A\"\n",
    "\n",
    "                if not any([title, price, rating, rating_count, image_url, product_url]) or all(\n",
    "                        [x == \"N/A\" for x in [title, price, rating, rating_count, monthly_sales, image_url, product_url]]):\n",
    "                    continue\n",
    "                # 写入CSV文件\n",
    "                writer.writerow([title, price, rating, rating_count, asin, monthly_sales, image_url, product_url])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing item with ASIN {asin}: {e}\")\n",
    "\n",
    "        # 尝试找到“Next”按钮并点击进入下一页\n",
    "        try:\n",
    "            next_button = driver.find_element(By.XPATH, '//a[contains(@class, \"s-pagination-next\")]')\n",
    "            driver.execute_script(\"arguments[0].click();\", next_button)  # 点击按钮\n",
    "            time.sleep(3)  # 等待新页面加载\n",
    "        except:\n",
    "            print(\"No 'Next' button found or unable to click. Ending extraction.\")\n",
    "            break\n",
    "\n",
    "print(\"Data extraction completed and saved to 'amazon_pet_memorial.csv'\")\n",
    "\n",
    "import csv\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import time\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"清除多余的换行符、空格和特殊字符\"\"\"\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "\n",
    "def extract_star_rating(text):\n",
    "    \"\"\"从星级文本提取数值\"\"\"\n",
    "    match = re.search(r'(\\d+\\.\\d+|\\d+)', text)\n",
    "    return match.group(0) if match else \"N/A\"\n",
    "\n",
    "\n",
    "def extract_percentage(text):\n",
    "    \"\"\"提取百分比值\"\"\"\n",
    "    return text.strip('%') if text else \"N/A\"\n",
    "\n",
    "\n",
    "def extract_date(text):\n",
    "    \"\"\"清理和标准化日期\"\"\"\n",
    "    # 假设日期格式为 'Reviewed in the United States on June 11, 2023'\n",
    "    match = re.search(r'on (.*)', text)\n",
    "    return match.group(1).strip() if match else \"N/A\"\n",
    "\n",
    "def scroll_until_element_found(driver, selector, timeout=30):\n",
    "    # 滚动页面直到找到指定的元素或超时\n",
    "    end_time = time.time() + timeout\n",
    "    while time.time() < end_time:\n",
    "        try:\n",
    "            element = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "            print(f\"找到元素，选择器：'{selector}'\")\n",
    "            return element\n",
    "        except NoSuchElementException:\n",
    "            print(f\"滚动页面 - 选择器 '{selector}' 的元素尚未找到\")\n",
    "            driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "            time.sleep(1)\n",
    "    raise TimeoutException(f\"在 {timeout} 秒内未找到选择器为 {selector} 的元素\")\n",
    "\n",
    "\n",
    "def scroll_to_bottom(driver):\n",
    "    # 滚动页面到底部，用于加载更多内容\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(3)  # 等待内容加载\n",
    "\n",
    "\n",
    "def append_star_ratings(input_file, output_file):\n",
    "    # 主函数，用于读取输入文件、提取星级和评论数据并保存到输出文件\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(\"https://www.amazon.com/sspa/click?ie=UTF8&spc=MTo3MDU3Nzg5NDQyOTA5OTk4OjE3MzEwNjU5NjI6c3BfYXRmOjIwMDA0MTU2OTMzNDMyMTo6MDo6&url=%2FMemorial-Markers-Tombstones-Outdoor-Sympaty%2Fdp%2FB07PDBY43T%2Fref%3Dsr_1_1_sspa%3Fcrid%3D2XEALO4SBIQ18%26dib%3DeyJ2IjoiMSJ9.hF8za7UiCXUjLAl8wSr5Dy_xXEyVFY0k8wIXA91D9QVeZm27E-1RowcJh-LR-oyp4xx6y4WLp3j-JHGrVpvXnS4am11gqNJXxjNxPS9wFSWJp7wSO77zUUSRRXP9r0iXo08-wH0pnqcA8HCdsaZA_3o27pxeua9C1EPC4w_1z1hHr9kdYsxNJPWRWPYG4s4AxDk1Beo4yMySWuloyDevBueeSN-F935k5A7lQxHOxdbLMuER9BZ07cQ_J0c3tMsQQmuN6kmIVG_o2eLrMw7vgln08Rhd1QB9a5qdfnWMmrs.FP6LiiV8CmZgG5y8AzdEC-JpHzJ5C3eYLPXMxclBV2k%26dib_tag%3Dse%26keywords%3Dpet%2Bmemorial%26qid%3D1731065962%26sprefix%3Dpet%2Bmemorial%252Caps%252C707%26sr%3D8-1-spons%26sp_csd%3Dd2lkZ2V0TmFtZT1zcF9hdGY%26psc%3D1\")\n",
    "    if input(\"是否已登录完毕，语言是否已切换完毕？（完成请摁1）\") == 1:\n",
    "        pass\n",
    "\n",
    "    with open(input_file, 'r', newline='', encoding='utf-8') as infile, \\\n",
    "            open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "\n",
    "        headers = next(reader)\n",
    "        writer.writerow(headers + [\"5 stars\", \"4 stars\", \"3 stars\", \"2 stars\", \"1 star\", \"Total Ratings with Reviews\"])\n",
    "\n",
    "        for row in reader:\n",
    "            product_url = row[7]  # 假设产品URL在第8列\n",
    "            asin = row[4]  # 假设ASIN在第5列\n",
    "            if product_url == \"N/A\":\n",
    "                # 如果产品URL为空，直接写入“N/A”\n",
    "                writer.writerow(row + [\"N/A\"] * 6)\n",
    "                continue\n",
    "\n",
    "            print(f\"打开产品页面: {product_url}\")\n",
    "            driver.get(product_url)\n",
    "            time.sleep(5)  # 等待页面加载\n",
    "\n",
    "            # 尝试点击“See all reviews”链接以查看所有评论\n",
    "            try:\n",
    "                see_more_reviews_link = scroll_until_element_found(driver, 'a[data-hook=\"see-all-reviews-link-foot\"]')\n",
    "                see_more_reviews_link.click()\n",
    "                print(\"点击 'See more reviews'\")\n",
    "                time.sleep(5)  # 等待页面加载\n",
    "            except TimeoutException:\n",
    "                print(f\"找不到 'See more reviews' 链接，跳过该产品: {product_url}\")\n",
    "                writer.writerow(row + [\"N/A\"] * 6)\n",
    "                continue\n",
    "\n",
    "            current_url = driver.current_url  # 获取当前页面的URL\n",
    "            # 提取星级比例\n",
    "            try:\n",
    "                scroll_until_element_found(driver, 'ul#histogramTable')  # 滚动到星级数据部分\n",
    "                stars = driver.find_elements(By.CSS_SELECTOR,\n",
    "                                             'ul#histogramTable .a-align-center .a-text-right span')\n",
    "                star_data = [stars[i].get_attribute(\"textContent\").strip().strip('%') for i in range(5)]  # 提取5个星级比例\n",
    "                print(star_data)\n",
    "                # 如果不足5个星级比例，用“N/A”补充\n",
    "                while len(star_data) < 5:\n",
    "                    star_data.append(\"N/A\")\n",
    "\n",
    "                # 切换到“包含图片和视频的评论”页面\n",
    "                media_only_url = current_url.replace(\"ref=cm_cr_arp_d_viewopt_actns\",\"ref=cm_cr_arp_d_viewopt_mdrvw\").replace(\"mediaType=all_contents\", \"mediaType=media_reviews_only\")\n",
    "                print(f\"切换到“仅图片和视频评论”页面，URL: {media_only_url}\")\n",
    "                driver.get(media_only_url)\n",
    "                time.sleep(5)  # 等待页面加载\n",
    "\n",
    "                # 尝试获取带图片和视频的总评论数量\n",
    "                try:\n",
    "                    total_ratings_text = driver.find_element(By.CSS_SELECTOR,\n",
    "                                                             'div[data-hook=\"cr-filter-info-review-rating-count\"]').text\n",
    "                    print(f\"带图片和视频的评论总数: {total_ratings_text}\")\n",
    "                except NoSuchElementException:\n",
    "                    total_ratings_text = \"N/A\"\n",
    "                    print(\"未找到带图片和视频的评论总数，添加 'N/A'。\")\n",
    "\n",
    "            except TimeoutException:\n",
    "                print(f\"未找到星级数据，跳过该产品: {product_url}\")\n",
    "                writer.writerow(row + [\"N/A\"] * 6)\n",
    "                continue\n",
    "\n",
    "            # 写入星级数据和带图片的评论总数\n",
    "            writer.writerow(row + star_data + [total_ratings_text])\n",
    "\n",
    "            # 切换到全部评论页面\n",
    "            media_only_url = current_url.replace(\"ref=cm_cr_arp_d_viewopt_mdrvw\",\n",
    "                                                 \"ref=cm_cr_arp_d_viewopt_actns\").replace(\n",
    "                \"mediaType=media_reviews_only\", \"mediaType=all_contents\")\n",
    "            print(f\"切换到“全部评论”网址: {media_only_url}\")\n",
    "            driver.get(media_only_url)\n",
    "            time.sleep(5)  # 等待页面加载\n",
    "\n",
    "            # 提取每条评论的详细信息\n",
    "            review_data = []\n",
    "            while True:\n",
    "                scroll_to_bottom(driver)  # 滚动到底部以加载更多评论\n",
    "                reviews = driver.find_element(By.CSS_SELECTOR, \"#cm_cr-review_list\").find_elements(By.CSS_SELECTOR, 'div[data-hook=\"review\"]')[:10]\n",
    "\n",
    "                for review in reviews:\n",
    "                    try:\n",
    "                        reviewer = clean_text(review.find_element(By.CSS_SELECTOR, 'span.a-profile-name').text)\n",
    "                    except NoSuchElementException:\n",
    "                        reviewer = \"N/A\"\n",
    "\n",
    "                    # 提取评分\n",
    "                    try:\n",
    "                        rating = extract_star_rating(\n",
    "                            review.find_element(By.CSS_SELECTOR,\n",
    "                                                'i[data-hook=\"review-star-rating\"] span').get_attribute(\n",
    "                                \"textContent\"))\n",
    "                    except NoSuchElementException:\n",
    "                        rating = \"N/A\"\n",
    "\n",
    "                    # 清洗标题\n",
    "                    try:\n",
    "                        title = clean_text(\n",
    "                            review.find_element(By.CSS_SELECTOR, 'a[data-hook=\"review-title\"]').get_attribute(\n",
    "                                \"textContent\"))\n",
    "                    except NoSuchElementException:\n",
    "                        title = \"N/A\"\n",
    "\n",
    "                    # 提取日期\n",
    "                    try:\n",
    "                        date = extract_date(\n",
    "                            review.find_element(By.CSS_SELECTOR, 'span[data-hook=\"review-date\"]').text)\n",
    "                    except NoSuchElementException:\n",
    "                        date = \"N/A\"\n",
    "\n",
    "                    # 清洗评论内容\n",
    "                    try:\n",
    "                        body = clean_text(\n",
    "                            review.find_element(By.CSS_SELECTOR, 'span[data-hook=\"review-body\"] span').text)\n",
    "                    except NoSuchElementException:\n",
    "                        body = \"N/A\"\n",
    "\n",
    "                    # 处理图片链接\n",
    "                    try:\n",
    "                        images = \"; \".join([img.get_attribute('src')\n",
    "                                            for img in\n",
    "                                            review.find_elements(By.CSS_SELECTOR, 'img[data-hook=\"review-image-tile\"]')\n",
    "                                            if img.get_attribute('src')])\n",
    "                    except NoSuchElementException:\n",
    "                        images = \"N/A\"\n",
    "\n",
    "                    print([reviewer, rating, title, date, body, \"; \".join(images)])\n",
    "                    review_data.append([reviewer, rating, title, date, body, \"; \".join(images)])\n",
    "\n",
    "                # 检查是否有下一页评论\n",
    "                try:\n",
    "                    next_page = driver.find_element(By.CSS_SELECTOR, 'li.a-last a')\n",
    "                    next_page_url = next_page.get_attribute('href')\n",
    "                    driver.get(next_page_url)\n",
    "                    time.sleep(5)  # 等待页面加载\n",
    "                except NoSuchElementException:\n",
    "                    print(\"没有更多评论页。\")\n",
    "                    break\n",
    "\n",
    "            # 将评论数据写入一个以 ASIN 命名的单独 CSV 文件\n",
    "            output_file_name = f\"reviews/{asin}.csv\"\n",
    "            with open(output_file_name, 'w', newline='', encoding='utf-8') as review_file:\n",
    "                review_writer = csv.writer(review_file)\n",
    "                review_writer.writerow([\"Reviewer\", \"Rating\", \"Title\", \"Date\", \"Review Text\", \"Image URLs\"])\n",
    "                review_writer.writerows(review_data)\n",
    "\n",
    "            print(f\"评论已保存到 {output_file_name}\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "# 示例用法\n",
    "append_star_ratings('amazon_pet_memorial.csv', 'updated_amazon_pet_memorial.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
