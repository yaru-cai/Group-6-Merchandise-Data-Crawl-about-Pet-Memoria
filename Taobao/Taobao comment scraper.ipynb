{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import openpyxl as op\n",
    "import time\n",
    "import threading\n",
    "\n",
    "\n",
    "# Initialize the WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", ['enable-automation'])\n",
    "options.add_argument('--disable-blink-features')   \n",
    "options.add_argument('--disable-blink-features=AutomationControlled')   \n",
    "options.add_argument('--disable-gpu')  \n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.maximize_window()\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# Comment scrape function\n",
    "def scrape_comments(product_url):\n",
    "    driver.get(product_url)\n",
    "    time.sleep(5)  \n",
    "    if input('请手动登录，确认界面加载完毕，输入数字“1”开始爬取-->') == 1:\n",
    "        pass\n",
    "    # Complete Login by scanning QR code and wait for the page to load\n",
    "    \n",
    "    # Navigate to the comments section\n",
    "    comments_tab = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, '.ShowButton--o4XEG7ih')))\n",
    "    comments_tab.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    if input('确认界面加载完毕，输入数字“1”开始爬取-->') == 1:\n",
    "        pass\n",
    "     # Wait for the comments to load\n",
    "    comments_data = []\n",
    "    comments = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.Comment--KkPcz74T')))\n",
    "    \n",
    "       \n",
    "    for comment in comments:\n",
    "       user = comment.find_element(By.CSS_SELECTOR, '.userInfo--ccnYGw2O .userName--mmxkxkd0').text\n",
    "       content = comment.find_element(By.CSS_SELECTOR, '.content--FpIOzHeP').text\n",
    "       date = comment.find_element(By.CSS_SELECTOR, '.meta--TDfRej2n').text\n",
    "       \n",
    "           \n",
    "       comments_data.append({\n",
    "           'User': user,\n",
    "           'Content': content,\n",
    "           'Date and style': date\n",
    "           })\n",
    "    return comments_data\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "# Save data to Excel \n",
    "def save_to_excel(comments_data, filename):\n",
    "    wb = op.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Comments\"\n",
    "\n",
    "    # Create header\n",
    "    headers = ['User', 'Content', 'Date and style']\n",
    "    for col_num, header in enumerate(headers, 1):\n",
    "        ws.cell(row=1, column=col_num, value=header)\n",
    "\n",
    "    # Write data\n",
    "    for row_num, comment in enumerate(comments_data, 2):\n",
    "        ws.cell(row=row_num, column=1, value=comment['User'])\n",
    "        ws.cell(row=row_num, column=2, value=comment['Content'])\n",
    "        ws.cell(row=row_num, column=3, value=comment['Date and style'])\n",
    "       \n",
    "\n",
    "    wb.save(filename)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "# Input products URL and Excel file name\n",
    "if __name__ == '__main__':\n",
    "    product_url = input(\"Enter the product URL: \")\n",
    "    product_url = 'https:' + product_url\n",
    "    filename = input(\"Enter the filename to save the comments: \")\n",
    "    Filename = filename + '(评论).xlsx'\n",
    "    \n",
    "    comments_data = scrape_comments(product_url)\n",
    "    save_to_excel(comments_data, Filename)\n",
    "\n",
    "    driver.quit"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
